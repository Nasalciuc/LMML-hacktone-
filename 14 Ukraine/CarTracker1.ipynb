{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24bef809-1870-4229-ad3e-28ae30fdcb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ char_1.mp4 ‚Üí T (score=0.077)\n",
      "‚úÖ char_2.mp4 ‚Üí M (score=0.110)\n",
      "‚úÖ char_3.mp4 ‚Üí A (score=0.064)\n",
      "‚úÖ char_4.mp4 ‚Üí W (score=0.114)\n",
      "‚úÖ char_5.mp4 ‚Üí Q (score=0.091)\n",
      "‚úÖ char_6.mp4 ‚Üí A (score=0.092)\n",
      "\n",
      "üèÅ Final FLAG: FLAG{TMAWQA}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- Helper: extract trajectory without showing any window ---\n",
    "def extract_trajectory(video_path, lower=(0, 50, 50), upper=(10, 255, 255)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    positions = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        lower_np = np.array(lower, dtype=np.uint8)\n",
    "        upper_np = np.array(upper, dtype=np.uint8)\n",
    "        mask = cv2.inRange(hsv, lower_np, upper_np)\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if contours:\n",
    "            c = max(contours, key=cv2.contourArea)\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            positions.append((x + w // 2, y + h // 2))\n",
    "    cap.release()\n",
    "    return positions\n",
    "\n",
    "# --- Helper: draw trajectory to image ---\n",
    "def trajectory_to_image(positions, size=(400, 400)):\n",
    "    img = np.zeros(size + (3,), dtype=np.uint8)\n",
    "    for i in range(1, len(positions)):\n",
    "        cv2.line(img, positions[i - 1], positions[i], (255, 255, 255), 3)\n",
    "    return img\n",
    "\n",
    "# --- Helper: match letter shape ---\n",
    "def compare_with_letters(img):\n",
    "    letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "    scores = {}\n",
    "    for ch in letters:\n",
    "        temp = np.zeros_like(img)\n",
    "        cv2.putText(temp, ch, (100, 300), cv2.FONT_HERSHEY_SIMPLEX, 6, (255, 255, 255), 15)\n",
    "        score = cv2.matchTemplate(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY),\n",
    "                                  cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY),\n",
    "                                  cv2.TM_CCOEFF_NORMED)[0][0]\n",
    "        scores[ch] = score\n",
    "    return max(scores, key=scores.get), max(scores.values())\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "video_dir = \"videos\"\n",
    "flag_letters = []\n",
    "\n",
    "for i in range(1, 7):\n",
    "    path = os.path.join(video_dir, f\"char_{i}.mp4\")\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"‚ùå Missing: {path}\")\n",
    "        continue\n",
    "    positions = extract_trajectory(path)\n",
    "    traj_img = trajectory_to_image(positions)\n",
    "    letter, score = compare_with_letters(traj_img)\n",
    "    flag_letters.append(letter)\n",
    "    print(f\"‚úÖ {os.path.basename(path)} ‚Üí {letter} (score={score:.3f})\")\n",
    "\n",
    "flag = \"FLAG{\" + \"\".join(flag_letters) + \"}\"\n",
    "print(\"\\nüèÅ Final FLAG:\", flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c3906-20ea-4d97-a93a-bff900665415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
